import os
import sys
import warnings
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from io import StringIO
import traceback
import streamlit as st
from scipy import stats
from typing import Dict, List, Any

# LangChain imports
from langchain.agents import AgentType, initialize_agent, Tool
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage

# ConfiguraÃ§Ãµes
warnings.filterwarnings('ignore')
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

# ============================================
# CONFIGURAÃ‡ÃƒO DA PÃGINA STREAMLIT
# ============================================

st.set_page_config(
    page_title="Agente EDA AutÃ´nomo",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================
# CLASSE DE GERENCIAMENTO DE DADOS
# ============================================

class DataManager:
    """Gerencia carregamento e acesso aos dados CSV"""

    def __init__(self):
        self.df = None
        self.filename = None
        self.load_history = []

    def load_csv(self, filepath):
        """Carrega arquivo CSV com tratamento de erros robusto"""
        try:
            # Tenta diferentes encodings
            for encoding in ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']:
                try:
                    self.df = pd.read_csv(filepath, encoding=encoding)
                    break
                except UnicodeDecodeError:
                    continue

            if self.df is None:
                return "Erro: NÃ£o foi possÃ­vel decodificar o arquivo CSV"

            self.filename = os.path.basename(filepath)
            self.load_history.append({
                'timestamp': datetime.now(),
                'filename': self.filename,
                'shape': self.df.shape
            })

            return f"""âœ… Arquivo carregado com sucesso!

ğŸ“Š InformaÃ§Ãµes bÃ¡sicas:
- Nome: {self.filename}
- Linhas: {self.df.shape[0]:,}
- Colunas: {self.df.shape[1]}
- MemÃ³ria: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB

ğŸ“‹ Colunas disponÃ­veis:
{', '.join(self.df.columns.tolist())}

ğŸ” Tipos de dados:
{self.df.dtypes.value_counts().to_dict()}
"""
        except Exception as e:
            return f"âŒ Erro ao carregar arquivo: {str(e)}"

    def get_dataframe(self):
        """Retorna o DataFrame atual"""
        return self.df

    def get_info(self):
        """Retorna informaÃ§Ãµes sobre o dataset carregado"""
        if self.df is None:
            return "Nenhum arquivo carregado ainda."

        buffer = StringIO()
        self.df.info(buf=buffer)
        return buffer.getvalue()

# ============================================
# AMBIENTE PYTHON SEGURO
# ============================================

class SafePythonREPL:
    """Ambiente Python REPL seguro com acesso ao DataFrame"""

    def __init__(self):
        self.globals_dict = {
            'pd': pd,
            'np': np,
            'plt': plt,
            'sns': sns,
            'df': None,
        }
        self.execution_history = []
        self.last_plot_path = None

    def run(self, code: str) -> str:
        """Executa cÃ³digo Python com seguranÃ§a"""
        try:
            self.last_plot_path = None
            
            # Atualiza referÃªncia ao DataFrame atual
            if 'data_manager' in st.session_state:
                self.globals_dict['df'] = st.session_state.data_manager.get_dataframe()

            if self.globals_dict['df'] is None:
                return "âš ï¸ Nenhum DataFrame carregado. Carregue um arquivo CSV primeiro."

            # Captura stdout
            old_stdout = sys.stdout
            sys.stdout = captured_output = StringIO()

            # Executa cÃ³digo
            exec(code, self.globals_dict)

            # Restaura stdout
            sys.stdout = old_stdout
            output = captured_output.getvalue()

            # Registra histÃ³rico
            self.execution_history.append({
                'timestamp': datetime.now(),
                'code': code,
                'success': True
            })

            # Se gerou um plot, salva e retorna caminho
            if plt.get_fignums():
                plot_path = f"plot_{len(self.execution_history)}.png"
                plt.savefig(plot_path, dpi=150, bbox_inches='tight')
                self.last_plot_path = plot_path
                
                # Adiciona o plot Ã  lista de plots do Streamlit
                if 'plots' not in st.session_state:
                    st.session_state.plots = []
                st.session_state.plots.append(plot_path)
                
                plt.close('all')
                output += f"\nğŸ“Š GrÃ¡fico gerado!"

            return output if output else "âœ… CÃ³digo executado com sucesso (sem output)."

        except Exception as e:
            self.execution_history.append({
                'timestamp': datetime.now(),
                'code': code,
                'success': False,
                'error': str(e)
            })
            return f"âŒ Erro na execuÃ§Ã£o:\n{traceback.format_exc()}"
    
    def get_last_plot(self):
        """Retorna o caminho do Ãºltimo grÃ¡fico gerado"""
        return self.last_plot_path

# ============================================
# FERRAMENTAS PERSONALIZADAS
# ============================================

class DataAnalyzerTool:
    """Ferramenta avanÃ§ada para anÃ¡lise exploratÃ³ria de dados"""
    
    def __init__(self):
        self.last_analysis = None
    
    def get_basic_stats(self, df: pd.DataFrame) -> str:
        """Retorna estatÃ­sticas bÃ¡sicas do dataset"""
        try:
            stats_info = {
                'shape': df.shape,
                'column_types': {
                    'numeric': df.select_dtypes(include=[np.number]).columns.tolist(),
                    'categorical': df.select_dtypes(include=['object']).columns.tolist(),
                    'datetime': df.select_dtypes(include=['datetime']).columns.tolist()
                },
                'missing_values': df.isnull().sum().to_dict(),
                'memory_usage': df.memory_usage(deep=True).sum(),
                'duplicated_rows': df.duplicated().sum()
            }
            
            # EstatÃ­sticas para colunas numÃ©ricas
            numeric_stats = {}
            for col in stats_info['column_types']['numeric']:
                numeric_stats[col] = {
                    'mean': float(df[col].mean()),
                    'median': float(df[col].median()),
                    'std': float(df[col].std()),
                    'min': float(df[col].min()),
                    'max': float(df[col].max()),
                    'q25': float(df[col].quantile(0.25)),
                    'q75': float(df[col].quantile(0.75)),
                    'skewness': float(stats.skew(df[col].dropna())),
                    'kurtosis': float(stats.kurtosis(df[col].dropna()))
                }
            
            stats_info['numeric_stats'] = numeric_stats
            
            # Formata output
            output = f"""
ğŸ“Š ESTATÃSTICAS BÃSICAS DO DATASET

ğŸ“ DimensÃµes: {stats_info['shape'][0]:,} linhas x {stats_info['shape'][1]} colunas
ğŸ’¾ Uso de memÃ³ria: {stats_info['memory_usage'] / 1024**2:.2f} MB
ğŸ”„ Linhas duplicadas: {stats_info['duplicated_rows']}

ğŸ“‹ TIPOS DE COLUNAS:
  â€¢ NumÃ©ricas: {len(stats_info['column_types']['numeric'])} - {', '.join(stats_info['column_types']['numeric'])}
  â€¢ CategÃ³ricas: {len(stats_info['column_types']['categorical'])} - {', '.join(stats_info['column_types']['categorical'])}
  â€¢ Data/Hora: {len(stats_info['column_types']['datetime'])} - {', '.join(stats_info['column_types']['datetime'])}

âŒ VALORES AUSENTES:
"""
            missing = {k: v for k, v in stats_info['missing_values'].items() if v > 0}
            if missing:
                for col, count in missing.items():
                    pct = (count / stats_info['shape'][0]) * 100
                    output += f"  â€¢ {col}: {count} ({pct:.2f}%)\n"
            else:
                output += "  âœ… Nenhum valor ausente!\n"
            
            output += "\nğŸ“ˆ ESTATÃSTICAS NUMÃ‰RICAS:\n"
            for col, stats_dict in numeric_stats.items():
                output += f"\n  {col}:\n"
                output += f"    MÃ©dia: {stats_dict['mean']:.2f} | Mediana: {stats_dict['median']:.2f}\n"
                output += f"    Desvio PadrÃ£o: {stats_dict['std']:.2f}\n"
                output += f"    MÃ­n: {stats_dict['min']:.2f} | MÃ¡x: {stats_dict['max']:.2f}\n"
                output += f"    Q1: {stats_dict['q25']:.2f} | Q3: {stats_dict['q75']:.2f}\n"
                output += f"    Assimetria: {stats_dict['skewness']:.3f} | Curtose: {stats_dict['kurtosis']:.3f}\n"
            
            return output
            
        except Exception as e:
            return f"âŒ Erro ao calcular estatÃ­sticas: {str(e)}"
    
    def detect_outliers(self, df: pd.DataFrame, method: str = 'iqr') -> str:
        """Detecta outliers usando diferentes mÃ©todos"""
        try:
            outliers = {}
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            
            if len(numeric_columns) == 0:
                return "âš ï¸ Nenhuma coluna numÃ©rica encontrada para detecÃ§Ã£o de outliers."
            
            for col in numeric_columns:
                if method == 'iqr':
                    Q1 = df[col].quantile(0.25)
                    Q3 = df[col].quantile(0.75)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    outlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)
                    outliers[col] = {
                        'count': outlier_mask.sum(),
                        'percentage': (outlier_mask.sum() / len(df)) * 100,
                        'lower_bound': float(lower_bound),
                        'upper_bound': float(upper_bound),
                        'indices': df[outlier_mask].index.tolist()[:10]  # Primeiros 10
                    }
                
                elif method == 'zscore':
                    z_scores = np.abs(stats.zscore(df[col].dropna()))
                    threshold = 3
                    outlier_mask = z_scores > threshold
                    outliers[col] = {
                        'count': outlier_mask.sum(),
                        'percentage': (outlier_mask.sum() / len(df)) * 100,
                        'threshold': threshold,
                        'indices': df[outlier_mask].index.tolist()[:10]
                    }
            
            # Formata output
            output = f"ğŸ” DETECÃ‡ÃƒO DE OUTLIERS (MÃ©todo: {method.upper()})\n\n"
            
            for col, info in outliers.items():
                if info['count'] > 0:
                    output += f"ğŸ“Š {col}:\n"
                    output += f"  â€¢ Outliers encontrados: {info['count']} ({info['percentage']:.2f}%)\n"
                    if method == 'iqr':
                        output += f"  â€¢ Limites: [{info['lower_bound']:.2f}, {info['upper_bound']:.2f}]\n"
                    else:
                        output += f"  â€¢ Threshold Z-score: {info['threshold']}\n"
                    if info['indices']:
                        output += f"  â€¢ Primeiros Ã­ndices: {info['indices']}\n"
                    output += "\n"
            
            if not any(info['count'] > 0 for info in outliers.values()):
                output += "âœ… Nenhum outlier detectado!\n"
            
            return output
            
        except Exception as e:
            return f"âŒ Erro ao detectar outliers: {str(e)}"
    
    def calculate_correlations(self, df: pd.DataFrame, threshold: float = 0.5) -> str:
        """Calcula e analisa correlaÃ§Ãµes entre variÃ¡veis numÃ©ricas"""
        try:
            numeric_df = df.select_dtypes(include=[np.number])
            
            if len(numeric_df.columns) < 2:
                return "âš ï¸ Ã‰ necessÃ¡rio pelo menos 2 colunas numÃ©ricas para calcular correlaÃ§Ãµes."
            
            corr_matrix = numeric_df.corr()
            
            # Encontra correlaÃ§Ãµes fortes
            strong_correlations = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_val = corr_matrix.iloc[i, j]
                    if abs(corr_val) >= threshold:
                        strong_correlations.append({
                            'var1': corr_matrix.columns[i],
                            'var2': corr_matrix.columns[j],
                            'correlation': float(corr_val)
                        })
            
            # Ordena por valor absoluto
            strong_correlations.sort(key=lambda x: abs(x['correlation']), reverse=True)
            
            # Formata output
            output = f"ğŸ”— ANÃLISE DE CORRELAÃ‡Ã•ES (threshold: {threshold})\n\n"
            output += f"ğŸ“Š Matriz de correlaÃ§Ã£o: {len(numeric_df.columns)}x{len(numeric_df.columns)}\n"
            output += f"ğŸ” CorrelaÃ§Ãµes fortes encontradas: {len(strong_correlations)}\n\n"
            
            if strong_correlations:
                output += "ğŸ“ˆ CORRELAÃ‡Ã•ES MAIS FORTES:\n"
                for i, corr in enumerate(strong_correlations[:10], 1):  # Top 10
                    strength = "Muito forte" if abs(corr['correlation']) > 0.8 else "Forte"
                    direction = "positiva" if corr['correlation'] > 0 else "negativa"
                    output += f"{i}. {corr['var1']} â†” {corr['var2']}\n"
                    output += f"   CorrelaÃ§Ã£o: {corr['correlation']:.3f} ({strength} {direction})\n\n"
            else:
                output += "â„¹ï¸ Nenhuma correlaÃ§Ã£o forte encontrada acima do threshold.\n"
            
            # Adiciona matriz completa
            output += "\nğŸ“‹ MATRIZ DE CORRELAÃ‡ÃƒO COMPLETA:\n"
            output += corr_matrix.to_string()
            
            return output
            
        except Exception as e:
            return f"âŒ Erro ao calcular correlaÃ§Ãµes: {str(e)}"
    
    def analyze_categorical(self, df: pd.DataFrame, top_n: int = 10) -> str:
        """Analisa variÃ¡veis categÃ³ricas"""
        try:
            cat_columns = df.select_dtypes(include=['object']).columns
            
            if len(cat_columns) == 0:
                return "âš ï¸ Nenhuma coluna categÃ³rica encontrada."
            
            output = f"ğŸ“Š ANÃLISE DE VARIÃVEIS CATEGÃ“RICAS\n"
            output += f"Total de colunas: {len(cat_columns)}\n\n"
            
            for col in cat_columns:
                unique_count = df[col].nunique()
                most_common = df[col].value_counts().head(top_n)
                missing = df[col].isnull().sum()
                
                output += f"ğŸ“‹ {col}:\n"
                output += f"  â€¢ Valores Ãºnicos: {unique_count}\n"
                output += f"  â€¢ Valores ausentes: {missing} ({(missing/len(df)*100):.2f}%)\n"
                output += f"  â€¢ Valores mais frequentes (top {min(top_n, len(most_common))}):\n"
                
                for value, count in most_common.items():
                    pct = (count / len(df)) * 100
                    output += f"    - {value}: {count} ({pct:.2f}%)\n"
                
                output += "\n"
            
            return output
            
        except Exception as e:
            return f"âŒ Erro ao analisar variÃ¡veis categÃ³ricas: {str(e)}"
    
    def run_analysis(self, analysis_type: str) -> str:
        """Executa anÃ¡lise baseada no tipo solicitado"""
        if 'data_manager' not in st.session_state:
            return "âš ï¸ DataManager nÃ£o inicializado."
        
        df = st.session_state.data_manager.get_dataframe()
        
        if df is None:
            return "âš ï¸ Nenhum DataFrame carregado."
        
        analysis_type = analysis_type.lower().strip()
        
        if 'basic' in analysis_type or 'estatistic' in analysis_type or 'resumo' in analysis_type:
            return self.get_basic_stats(df)
        
        elif 'outlier' in analysis_type:
            method = 'zscore' if 'zscore' in analysis_type or 'z-score' in analysis_type else 'iqr'
            return self.detect_outliers(df, method)
        
        elif 'correla' in analysis_type:
            threshold = 0.3 if 'fraca' in analysis_type else 0.5
            return self.calculate_correlations(df, threshold)
        
        elif 'categor' in analysis_type:
            return self.analyze_categorical(df)
        
        else:
            return f"""â„¹ï¸ Tipo de anÃ¡lise nÃ£o reconhecido: '{analysis_type}'

AnÃ¡lises disponÃ­veis:
- basic/estatisticas/resumo: EstatÃ­sticas bÃ¡sicas completas
- outlier/outliers: DetecÃ§Ã£o de outliers (IQR ou Z-score)
- correlacao/correlaÃ§Ãµes: AnÃ¡lise de correlaÃ§Ãµes
- categorica/categoricas: AnÃ¡lise de variÃ¡veis categÃ³ricas
"""

# InstÃ¢ncia global da ferramenta de anÃ¡lise
data_analyzer = DataAnalyzerTool()

def load_csv_tool(filepath: str) -> str:
    """Ferramenta para carregar arquivo CSV"""
    if 'data_manager' not in st.session_state:
        st.session_state.data_manager = DataManager()
    
    result = st.session_state.data_manager.load_csv(filepath)
    return result

def get_dataframe_info_tool(dummy: str = "") -> str:
    """Retorna informaÃ§Ãµes sobre o DataFrame carregado"""
    if 'data_manager' not in st.session_state or st.session_state.data_manager.df is None:
        return "Nenhum arquivo CSV foi carregado ainda. Use a ferramenta 'load_csv' primeiro."
    return st.session_state.data_manager.get_info()

# ============================================
# SISTEMA DE PROMPT DO AGENTE
# ============================================

SYSTEM_PROMPT = """VocÃª Ã© um Cientista de Dados Especialista em AnÃ¡lise ExploratÃ³ria de Dados (EDA).

ğŸ¯ SUA MISSÃƒO:
Ajudar usuÃ¡rios a explorar, analisar e extrair insights de arquivos CSV atravÃ©s de anÃ¡lises estatÃ­sticas e visualizaÃ§Ãµes.

ğŸ“Š DATASET ATUAL:
O DataFrame estÃ¡ disponÃ­vel na variÃ¡vel 'df'. Use-o diretamente em seus cÃ³digos Python.

ğŸ› ï¸ FERRAMENTAS DISPONÃVEIS:

1. **get_dataframe_info**: InformaÃ§Ãµes bÃ¡sicas sobre o dataset
   - Use PRIMEIRO quando carregar dados novos
   - Mostra colunas, tipos, shape

2. **data_analyzer**: AnÃ¡lises estatÃ­sticas avanÃ§adas (USE ESTA PRIMEIRO para anÃ¡lises)
   - "basic" â†’ EstatÃ­sticas completas (mÃ©dia, mediana, std, assimetria, curtose, missing values)
   - "outlier" â†’ DetecÃ§Ã£o de outliers (IQR ou Z-score)
   - "correlacao" â†’ CorrelaÃ§Ãµes entre variÃ¡veis numÃ©ricas
   - "categorica" â†’ AnÃ¡lise de variÃ¡veis categÃ³ricas
   
3. **python_repl**: CÃ³digo Python customizado
   - Use quando data_analyzer nÃ£o cobrir a anÃ¡lise necessÃ¡ria
   - Para visualizaÃ§Ãµes
   - Para anÃ¡lises temporais
   - Para transformaÃ§Ãµes especÃ­ficas

âš¡ FLUXO DE TRABALHO OTIMIZADO:

**Para perguntas sobre estatÃ­sticas/resumo:**
1. Use `data_analyzer` com "basic"
2. Interprete os resultados
âœ… RÃ¡pido e completo!

**Para perguntas sobre outliers:**
1. Use `data_analyzer` com "outlier"
2. Se precisar visualizar, use `python_repl` para grÃ¡fico
âœ… AnÃ¡lise + visualizaÃ§Ã£o!

**Para perguntas sobre correlaÃ§Ã£o:**
1. Use `data_analyzer` com "correlacao"
2. Se precisar heatmap, use `python_repl`
âœ… NÃºmeros + grÃ¡fico!

**Para anÃ¡lise de variÃ¡veis categÃ³ricas:**
1. Use `data_analyzer` com "categorica"
2. Se precisar grÃ¡ficos de barras, use `python_repl`

**Para visualizaÃ§Ãµes ou anÃ¡lises customizadas:**
1. Use `python_repl` diretamente

ğŸ“‹ EXEMPLOS DE USO:

Pergunta: "Quais as estatÃ­sticas bÃ¡sicas?"
â†’ Use: data_analyzer("basic")
â†’ Resultado: EstatÃ­sticas completas em segundos!

Pergunta: "Existem outliers?"
â†’ Use: data_analyzer("outlier")
â†’ Depois (opcional): python_repl para visualizar

Pergunta: "Quais variÃ¡veis estÃ£o correlacionadas?"
â†’ Use: data_analyzer("correlacao")
â†’ Depois (opcional): python_repl para heatmap

Pergunta: "Valores mais frequentes?"
â†’ Use: data_analyzer("categorica")

Pergunta: "TendÃªncias temporais?"
â†’ Use: python_repl (anÃ¡lise customizada)

Pergunta: "FaÃ§a grÃ¡fico de X"
â†’ Use: python_repl

âš ï¸ REGRAS CRÃTICAS:
1. **SEMPRE prefira data_analyzer** para anÃ¡lises estatÃ­sticas padrÃ£o
2. **Use python_repl** apenas para visualizaÃ§Ãµes ou anÃ¡lises nÃ£o-padrÃ£o
3. **SEJA DIRETO**: Execute ferramentas imediatamente, nÃ£o explique o que VAI fazer
4. **MOSTRE RESULTADOS**: Sempre apresente os nÃºmeros e interprete
5. **NÃƒO invente dados**: Use apenas o que as ferramentas retornam

ğŸ’¡ DICAS DE EFICIÃŠNCIA:
- data_analyzer Ã© mais rÃ¡pido que python_repl para anÃ¡lises padrÃ£o
- Combine ferramentas: data_analyzer para nÃºmeros + python_repl para grÃ¡ficos
- Uma ferramenta por vez: execute, analise resultado, depois decida prÃ³ximo passo

ğŸ§  LEMBRE-SE:
VocÃª Ã© um agente de AÃ‡ÃƒO, nÃ£o apenas de planejamento. Execute, mostre resultados, interprete.
"""

# ============================================
# INICIALIZAÃ‡ÃƒO DO AGENTE
# ============================================

@st.cache_resource
def create_agent(api_key, max_iter=15):
    """Cria e configura o agente LangChain"""
    
    # Configura a API key
    api_key = st.secrets["OPENAI_API_KEY"]
    os.environ["OPENAI_API_KEY"] = api_key
    
    # Modelo OpenAI
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1,
        max_tokens=4000
    )

    # MemÃ³ria conversacional
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="output"
    )
    
    # InstÃ¢ncia do Python REPL
    if 'python_repl' not in st.session_state:
        st.session_state.python_repl = SafePythonREPL()

    # Ferramentas disponÃ­veis
    tools = [
        Tool(
            name="get_dataframe_info",
            func=get_dataframe_info_tool,
            description="""Retorna informaÃ§Ãµes detalhadas sobre o DataFrame carregado.
            Use PRIMEIRO para conhecer as colunas, tipos de dados e estatÃ­sticas bÃ¡sicas.
            Input: qualquer string (serÃ¡ ignorada)
            Output: informaÃ§Ãµes completas do dataset"""
        ),
        Tool(
            name="data_analyzer",
            func=data_analyzer.run_analysis,
            description="""Ferramenta avanÃ§ada para anÃ¡lise exploratÃ³ria de dados.
            
            Tipos de anÃ¡lise disponÃ­veis:
            - "basic" ou "estatisticas" ou "resumo": EstatÃ­sticas descritivas completas
              (mÃ©dia, mediana, desvio padrÃ£o, assimetria, curtose, valores ausentes)
            
            - "outlier" ou "outliers": DetecÃ§Ã£o de outliers
              - Use "outlier iqr" para mÃ©todo IQR (padrÃ£o)
              - Use "outlier zscore" para mÃ©todo Z-score
            
            - "correlacao" ou "correlaÃ§Ãµes": AnÃ¡lise de correlaÃ§Ãµes entre variÃ¡veis numÃ©ricas
              - Use "correlacao fraca" para threshold 0.3
              - PadrÃ£o: threshold 0.5
            
            - "categorica" ou "categoricas": AnÃ¡lise de variÃ¡veis categÃ³ricas
              (valores Ãºnicos, frequÃªncias, valores mais comuns)
            
            Input: tipo de anÃ¡lise desejada (string)
            Output: anÃ¡lise detalhada formatada
            
            Exemplos de uso:
            - "basic" â†’ EstatÃ­sticas completas
            - "outlier iqr" â†’ Outliers pelo mÃ©todo IQR
            - "correlacao" â†’ CorrelaÃ§Ãµes fortes (>0.5)
            - "categorica" â†’ AnÃ¡lise das variÃ¡veis categÃ³ricas"""
        ),
        Tool(
            name="python_repl",
            description="""Executa cÃ³digo Python para anÃ¡lise de dados e visualizaÃ§Ãµes.
            O DataFrame estÃ¡ disponÃ­vel como 'df' (jÃ¡ carregado e pronto para uso).
            
            Bibliotecas disponÃ­veis: 
            - pandas (pd)
            - numpy (np) 
            - matplotlib.pyplot (plt)
            - seaborn (sns)
            
            Use para:
            - AnÃ¡lises customizadas nÃ£o cobertas pelo data_analyzer
            - VisualizaÃ§Ãµes: histogramas, boxplots, scatter plots, heatmaps
            - TransformaÃ§Ãµes de dados
            - AnÃ¡lises temporais
            - Filtros e agregaÃ§Ãµes especÃ­ficas
            
            IMPORTANTE: Sempre use print() para mostrar resultados!
            
            Input: cÃ³digo Python vÃ¡lido
            Output: resultado da execuÃ§Ã£o + grÃ¡ficos gerados"""
        )
    ]

    # Inicializa agente
    agent = initialize_agent(
        tools=tools,
        llm=llm,
        agent=AgentType.OPENAI_FUNCTIONS,
        memory=memory,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=max_iter,  # ConfigurÃ¡vel
        max_execution_time=120,
        early_stopping_method="generate",
        agent_kwargs={
            "system_message": SystemMessage(content=SYSTEM_PROMPT)
        }
    )

    return agent

# ============================================
# INICIALIZAÃ‡ÃƒO DO SESSION STATE
# ============================================

if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'data_manager' not in st.session_state:
    st.session_state.data_manager = DataManager()

if 'plots' not in st.session_state:
    st.session_state.plots = []

if 'python_repl' not in st.session_state:
    st.session_state.python_repl = SafePythonREPL()

# ============================================
# INTERFACE STREAMLIT
# ============================================

# Header
st.title("ğŸ¤– Agente AutÃ´nomo para AnÃ¡lise ExploratÃ³ria de Dados")
st.markdown("### ğŸ“Š Powered by LangChain + OpenAI GPT-4")

st.markdown("""
**Como usar:**
1. Configure sua API Key da OpenAI na barra lateral
2. FaÃ§a upload do seu arquivo CSV
3. FaÃ§a perguntas sobre os dados em linguagem natural
4. Receba anÃ¡lises, estatÃ­sticas e visualizaÃ§Ãµes
""")

st.divider()

api_key = st.secrets["OPENAI_API_KEY"]

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ ConfiguraÃ§Ãµes")
    
    # API Key
    # api_key = st.text_input(
    #     "OpenAI API Key",
    #     type="password",
    #     help="Cole sua chave API da OpenAI aqui"
    # )
    
    if api_key:
        st.success("âœ… API Key configurada!")
        
        # ConfiguraÃ§Ã£o de iteraÃ§Ãµes mÃ¡ximas
        max_iterations = st.slider(
            "MÃ¡ximo de iteraÃ§Ãµes do agente",
            min_value=5,
            max_value=30,
            value=15,
            step=5,
            help="NÃºmero mÃ¡ximo de passos que o agente pode executar. Aumente para anÃ¡lises mais complexas."
        )
        
        # Cria o agente com a API key e max_iterations
        if 'agent' not in st.session_state or st.session_state.get('api_key') != api_key or st.session_state.get('max_iter') != max_iterations:
            with st.spinner("Inicializando agente..."):
                st.session_state.agent = create_agent(api_key, max_iterations)
                st.session_state.api_key = api_key
                st.session_state.max_iter = max_iterations
    else:
        st.warning("âš ï¸ Configure sua API Key para comeÃ§ar")
    
    st.divider()
    
    # InformaÃ§Ãµes sobre ferramentas
    with st.expander("ğŸ› ï¸ Ferramentas do Agente"):
        st.markdown("""
        **Data Analyzer (AnÃ¡lises RÃ¡pidas):**
        - âš¡ EstatÃ­sticas bÃ¡sicas completas
        - ğŸ”— AnÃ¡lise de correlaÃ§Ãµes
        - ğŸ“Š AnÃ¡lise de variÃ¡veis categÃ³ricas
        
        **Python REPL (AnÃ¡lises Customizadas):**
        - ğŸ“ˆ VisualizaÃ§Ãµes e grÃ¡ficos
        - ğŸ” TransformaÃ§Ãµes especÃ­ficas
        - ğŸ¨ AnÃ¡lises nÃ£o-padrÃ£o
        
        ğŸ’¡ O agente escolhe automaticamente a melhor ferramenta!
        """)
    
    # Dicas de uso
    with st.expander("ğŸ’¡ Dicas para usar o agente"):
        st.markdown("""
        **Perguntas rÃ¡pidas (1-3 iteraÃ§Ãµes):**
        - "Mostre estatÃ­sticas bÃ¡sicas"
        - "Analise correlaÃ§Ãµes"
        - "VariÃ¡veis categÃ³ricas"
        
        **AnÃ¡lises mÃ©dias (5-10 iteraÃ§Ãµes):**
        - "Analise correlaÃ§Ã£o e crie heatmap"
        - "Detecte outliers e visualize"
        - "Compare grupos A e B"
        
        **AnÃ¡lises complexas (10-20 iteraÃ§Ãµes):**
        - "AnÃ¡lise exploratÃ³ria completa com grÃ¡ficos"
        - "Identifique padrÃµes temporais e tendÃªncias"
        - "AnÃ¡lise completa de todas as variÃ¡veis"
        
        âš¡ **Nova ferramenta Data Analyzer = Respostas mais rÃ¡pidas!**
        """)
    
    st.divider()
    
    # Upload de arquivo
    st.header("ğŸ“ Upload de Dados")
    uploaded_file = st.file_uploader(
        "Selecione um arquivo CSV",
        type=['csv'],
        help="FaÃ§a upload do arquivo CSV que deseja analisar"
    )
    
    if uploaded_file is not None:
        # Salva o arquivo temporariamente
        temp_path = f"temp_{uploaded_file.name}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        if st.button("ğŸš€ Carregar CSV", use_container_width=True):
            with st.spinner("Carregando arquivo..."):
                result = st.session_state.data_manager.load_csv(temp_path)
                st.success("Arquivo carregado!")
                with st.expander("ğŸ“Š InformaÃ§Ãµes do Dataset"):
                    st.text(result)
    
    st.divider()
    
    # BotÃ£o para limpar chat
    if st.button("ğŸ—‘ï¸ Limpar Conversa", use_container_width=True):
        st.session_state.messages = []
        st.session_state.plots = []
        st.rerun()
    
    # InformaÃ§Ãµes do dataset
    if st.session_state.data_manager.df is not None:
        st.divider()
        st.header("ğŸ“Š Dataset Info")
        df = st.session_state.data_manager.df
        st.metric("Linhas", f"{df.shape[0]:,}")
        st.metric("Colunas", df.shape[1])
        st.metric("MemÃ³ria", f"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

# Main content
col1, col2 = st.columns([2, 1])

with col1:
    st.header("ğŸ’¬ Conversa com o Agente")
    
    # Perguntas sugeridas
    if st.session_state.data_manager.df is not None and len(st.session_state.messages) == 0:
        st.info("ğŸ’¡ **Perguntas sugeridas para comeÃ§ar:**")
        col_a, col_b, col_c = st.columns(3)
        
        with col_a:
            if st.button("ğŸ“Š EstatÃ­sticas bÃ¡sicas", use_container_width=True):
                st.session_state.suggested_question = "Mostre as estatÃ­sticas bÃ¡sicas do dataset"
        
        with col_b:
            if st.button("ğŸ” Detectar outliers", use_container_width=True):
                st.session_state.suggested_question = "Detecte outliers nas variÃ¡veis numÃ©ricas"
        
        with col_c:
            if st.button("ğŸ”— AnÃ¡lise de correlaÃ§Ã£o", use_container_width=True):
                st.session_state.suggested_question = "Analise as correlaÃ§Ãµes entre variÃ¡veis e mostre as mais fortes"
        
        col_d, col_e, col_f = st.columns(3)
        
        with col_d:
            if st.button("ğŸ“‹ VariÃ¡veis categÃ³ricas", use_container_width=True):
                st.session_state.suggested_question = "Analise as variÃ¡veis categÃ³ricas e mostre os valores mais frequentes"
        
        with col_e:
            if st.button("ğŸ“ˆ AnÃ¡lise exploratÃ³ria completa", use_container_width=True):
                st.session_state.suggested_question = "FaÃ§a uma anÃ¡lise exploratÃ³ria completa incluindo estatÃ­sticas, outliers e correlaÃ§Ãµes"
        
        with col_f:
            if st.button("ğŸ“‰ VisualizaÃ§Ãµes", use_container_width=True):
                st.session_state.suggested_question = "Crie visualizaÃ§Ãµes das principais variÃ¡veis do dataset"
    
    # Container para mensagens
    chat_container = st.container(height=500)
    
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # Input de mensagem
    prompt = None
    
    # Verifica se hÃ¡ pergunta sugerida
    if 'suggested_question' in st.session_state:
        prompt = st.session_state.suggested_question
        del st.session_state.suggested_question
    else:
        prompt = st.chat_input("Digite sua pergunta sobre os dados...", disabled=not api_key)
    
    if prompt:
        if 'agent' not in st.session_state:
            st.error("âŒ Configure sua API Key primeiro!")
        elif st.session_state.data_manager.df is None:
            st.warning("âš ï¸ Carregue um arquivo CSV primeiro antes de fazer perguntas!")
        else:
            # Adiciona mensagem do usuÃ¡rio
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Processa resposta do agente
                with st.chat_message("assistant"):
                    with st.spinner("Analisando..."):
                        try:
                            response = st.session_state.agent.run(prompt)
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                        except Exception as e:
                            error_str = str(e)
                            
                            # Verifica se Ã© erro de limite de iteraÃ§Ãµes
                            if "iteration limit" in error_str.lower() or "time limit" in error_str.lower():
                                error_msg = """âš ï¸ **AnÃ¡lise muito complexa!**
                                
O agente atingiu o limite de iteraÃ§Ãµes. Isso pode acontecer quando:
- A anÃ¡lise requer muitos passos
- HÃ¡ muitas variÃ¡veis para processar
- A pergunta Ã© muito abrangente

**SugestÃµes:**
1. Aumente o limite de iteraÃ§Ãµes na sidebar (atualmente: {})
2. Divida sua pergunta em partes menores
3. Seja mais especÃ­fico sobre o que deseja analisar

ğŸ’¡ Tentarei responder com o que consegui processar atÃ© agora...
                                """.format(st.session_state.get('max_iter', 15))
                                
                                st.warning(error_msg)
                                
                                # Tenta obter resposta parcial se houver
                                if hasattr(st.session_state.agent, 'agent') and hasattr(st.session_state.agent.agent, 'return_values'):
                                    partial = st.session_state.agent.agent.return_values.get('output', 'AnÃ¡lise incompleta.')
                                    st.markdown(partial)
                                    st.session_state.messages.append({"role": "assistant", "content": error_msg + "\n\n" + partial})
                                else:
                                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
                            else:
                                # Outros erros
                                error_msg = f"âŒ **Erro ao processar:**\n```\n{error_str}\n```"
                                st.error(error_msg)
                                st.session_state.messages.append({"role": "assistant", "content": error_msg})
            
            st.rerun()

with col2:
    st.header("ğŸ“Š GrÃ¡ficos Gerados")
    
    if st.session_state.plots:
        for i, plot_path in enumerate(reversed(st.session_state.plots)):
            if os.path.exists(plot_path):
                st.image(plot_path, caption=f"GrÃ¡fico {len(st.session_state.plots) - i}", use_container_width=True)
                st.divider()
    else:
        st.info("Nenhum grÃ¡fico gerado ainda. PeÃ§a ao agente para criar visualizaÃ§Ãµes!")

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    Desenvolvido com â¤ï¸ usando LangChain e Streamlit
</div>
""", unsafe_allow_html=True)