import os
import sys
import warnings
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from io import StringIO
import traceback
import streamlit as st
from scipy import stats
from typing import Dict, List, Any

# LangChain imports
from langchain.agents import AgentType, initialize_agent, Tool
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage

# Configura√ß√µes
warnings.filterwarnings('ignore')
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

# ============================================
# CONFIGURA√á√ÉO DA P√ÅGINA STREAMLIT
# ============================================

st.set_page_config(
    page_title="Agente EDA Aut√¥nomo",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================
# CLASSE DE GERENCIAMENTO DE DADOS
# ============================================

class DataManager:
    """Gerencia carregamento e acesso aos dados CSV"""

    def __init__(self):
        self.df = None
        self.filename = None
        self.load_history = []

    def load_csv(self, filepath):
        """Carrega arquivo CSV com tratamento de erros robusto"""
        try:
            # Tenta diferentes encodings
            for encoding in ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']:
                try:
                    self.df = pd.read_csv(filepath, encoding=encoding)
                    break
                except UnicodeDecodeError:
                    continue

            if self.df is None:
                return "Erro: N√£o foi poss√≠vel decodificar o arquivo CSV"

            self.filename = os.path.basename(filepath)
            self.load_history.append({
                'timestamp': datetime.now(),
                'filename': self.filename,
                'shape': self.df.shape
            })

            return f"""‚úÖ Arquivo carregado com sucesso!

üìä Informa√ß√µes b√°sicas:
- Nome: {self.filename}
- Linhas: {self.df.shape[0]:,}
- Colunas: {self.df.shape[1]}
- Mem√≥ria: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB

üìã Colunas dispon√≠veis:
{', '.join(self.df.columns.tolist())}

üîç Tipos de dados:
{self.df.dtypes.value_counts().to_dict()}
"""
        except Exception as e:
            return f"‚ùå Erro ao carregar arquivo: {str(e)}"

    def get_dataframe(self):
        """Retorna o DataFrame atual"""
        return self.df

    def get_info(self):
        """Retorna informa√ß√µes sobre o dataset carregado"""
        if self.df is None:
            return "Nenhum arquivo carregado ainda."

        buffer = StringIO()
        self.df.info(buf=buffer)
        return buffer.getvalue()

# ============================================
# AMBIENTE PYTHON SEGURO
# ============================================

class SafePythonREPL:
    """Ambiente Python REPL seguro com acesso ao DataFrame"""

    def __init__(self):
        self.globals_dict = {
            'pd': pd,
            'np': np,
            'plt': plt,
            'sns': sns,
            'df': None,
        }
        self.execution_history = []
        self.last_plot_path = None

    def run(self, code: str) -> str:
        """Executa c√≥digo Python com seguran√ßa"""
        try:
            self.last_plot_path = None
            
            # Atualiza refer√™ncia ao DataFrame atual
            if 'data_manager' in st.session_state:
                self.globals_dict['df'] = st.session_state.data_manager.get_dataframe()

            if self.globals_dict['df'] is None:
                return "‚ö†Ô∏è Nenhum DataFrame carregado. Carregue um arquivo CSV primeiro."

            # Captura stdout
            old_stdout = sys.stdout
            sys.stdout = captured_output = StringIO()

            # Executa c√≥digo
            exec(code, self.globals_dict)

            # Restaura stdout
            sys.stdout = old_stdout
            output = captured_output.getvalue()

            # Registra hist√≥rico
            self.execution_history.append({
                'timestamp': datetime.now(),
                'code': code,
                'success': True
            })

            # Se gerou um plot, salva e retorna caminho
            if plt.get_fignums():
                plot_path = f"plot_{len(self.execution_history)}.png"
                plt.savefig(plot_path, dpi=150, bbox_inches='tight')
                self.last_plot_path = plot_path
                
                # Adiciona o plot √† lista de plots do Streamlit
                if 'plots' not in st.session_state:
                    st.session_state.plots = []
                st.session_state.plots.append(plot_path)
                
                plt.close('all')
                output += f"\nüìä Gr√°fico gerado!"

            return output if output else "‚úÖ C√≥digo executado com sucesso (sem output)."

        except Exception as e:
            self.execution_history.append({
                'timestamp': datetime.now(),
                'code': code,
                'success': False,
                'error': str(e)
            })
            return f"‚ùå Erro na execu√ß√£o:\n{traceback.format_exc()}"
    
    def get_last_plot(self):
        """Retorna o caminho do √∫ltimo gr√°fico gerado"""
        return self.last_plot_path

# ============================================
# FERRAMENTAS PERSONALIZADAS
# ============================================

class DataAnalyzerTool:
    """Ferramenta avan√ßada para an√°lise explorat√≥ria de dados"""
    
    def __init__(self):
        self.last_analysis = None
    
    def get_basic_stats(self, df: pd.DataFrame) -> str:
        """Retorna estat√≠sticas b√°sicas do dataset"""
        try:
            stats_info = {
                'shape': df.shape,
                'column_types': {
                    'numeric': df.select_dtypes(include=[np.number]).columns.tolist(),
                    'categorical': df.select_dtypes(include=['object']).columns.tolist(),
                    'datetime': df.select_dtypes(include=['datetime']).columns.tolist()
                },
                'missing_values': df.isnull().sum().to_dict(),
                'memory_usage': df.memory_usage(deep=True).sum(),
                'duplicated_rows': df.duplicated().sum()
            }
            
            # Estat√≠sticas para colunas num√©ricas
            numeric_stats = {}
            for col in stats_info['column_types']['numeric']:
                numeric_stats[col] = {
                    'mean': float(df[col].mean()),
                    'median': float(df[col].median()),
                    'std': float(df[col].std()),
                    'min': float(df[col].min()),
                    'max': float(df[col].max()),
                    'q25': float(df[col].quantile(0.25)),
                    'q75': float(df[col].quantile(0.75)),
                    'skewness': float(stats.skew(df[col].dropna())),
                    'kurtosis': float(stats.kurtosis(df[col].dropna()))
                }
            
            stats_info['numeric_stats'] = numeric_stats
            
            # Formata output
            output = f"""
üìä ESTAT√çSTICAS B√ÅSICAS DO DATASET

üìè Dimens√µes: {stats_info['shape'][0]:,} linhas x {stats_info['shape'][1]} colunas
üíæ Uso de mem√≥ria: {stats_info['memory_usage'] / 1024**2:.2f} MB
üîÑ Linhas duplicadas: {stats_info['duplicated_rows']}

üìã TIPOS DE COLUNAS:
  ‚Ä¢ Num√©ricas: {len(stats_info['column_types']['numeric'])} - {', '.join(stats_info['column_types']['numeric'])}
  ‚Ä¢ Categ√≥ricas: {len(stats_info['column_types']['categorical'])} - {', '.join(stats_info['column_types']['categorical'])}
  ‚Ä¢ Data/Hora: {len(stats_info['column_types']['datetime'])} - {', '.join(stats_info['column_types']['datetime'])}

‚ùå VALORES AUSENTES:
"""
            missing = {k: v for k, v in stats_info['missing_values'].items() if v > 0}
            if missing:
                for col, count in missing.items():
                    pct = (count / stats_info['shape'][0]) * 100
                    output += f"  ‚Ä¢ {col}: {count} ({pct:.2f}%)\n"
            else:
                output += "  ‚úÖ Nenhum valor ausente!\n"
            
            output += "\nüìà ESTAT√çSTICAS NUM√âRICAS:\n"
            for col, stats_dict in numeric_stats.items():
                output += f"\n  {col}:\n"
                output += f"    M√©dia: {stats_dict['mean']:.2f} | Mediana: {stats_dict['median']:.2f}\n"
                output += f"    Desvio Padr√£o: {stats_dict['std']:.2f}\n"
                output += f"    M√≠n: {stats_dict['min']:.2f} | M√°x: {stats_dict['max']:.2f}\n"
                output += f"    Q1: {stats_dict['q25']:.2f} | Q3: {stats_dict['q75']:.2f}\n"
                output += f"    Assimetria: {stats_dict['skewness']:.3f} | Curtose: {stats_dict['kurtosis']:.3f}\n"
            
            return output
            
        except Exception as e:
            return f"‚ùå Erro ao calcular estat√≠sticas: {str(e)}"
    
    def detect_outliers(self, df: pd.DataFrame, method: str = 'iqr') -> str:
        """Detecta outliers usando diferentes m√©todos"""
        try:
            outliers = {}
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            
            if len(numeric_columns) == 0:
                return "‚ö†Ô∏è Nenhuma coluna num√©rica encontrada para detec√ß√£o de outliers."
            
            for col in numeric_columns:
                if method == 'iqr':
                    Q1 = df[col].quantile(0.25)
                    Q3 = df[col].quantile(0.75)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    outlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)
                    outliers[col] = {
                        'count': outlier_mask.sum(),
                        'percentage': (outlier_mask.sum() / len(df)) * 100,
                        'lower_bound': float(lower_bound),
                        'upper_bound': float(upper_bound),
                        'indices': df[outlier_mask].index.tolist()[:10]  # Primeiros 10
                    }
                
                elif method == 'zscore':
                    z_scores = np.abs(stats.zscore(df[col].dropna()))
                    threshold = 3
                    outlier_mask = z_scores > threshold
                    outliers[col] = {
                        'count': outlier_mask.sum(),
                        'percentage': (outlier_mask.sum() / len(df)) * 100,
                        'threshold': threshold,
                        'indices': df[outlier_mask].index.tolist()[:10]
                    }
            
            # Formata output
            output = f"üîç DETEC√á√ÉO DE OUTLIERS (M√©todo: {method.upper()})\n\n"
            
            for col, info in outliers.items():
                if info['count'] > 0:
                    output += f"üìä {col}:\n"
                    output += f"  ‚Ä¢ Outliers encontrados: {info['count']} ({info['percentage']:.2f}%)\n"
                    if method == 'iqr':
                        output += f"  ‚Ä¢ Limites: [{info['lower_bound']:.2f}, {info['upper_bound']:.2f}]\n"
                    else:
                        output += f"  ‚Ä¢ Threshold Z-score: {info['threshold']}\n"
                    if info['indices']:
                        output += f"  ‚Ä¢ Primeiros √≠ndices: {info['indices']}\n"
                    output += "\n"
            
            if not any(info['count'] > 0 for info in outliers.values()):
                output += "‚úÖ Nenhum outlier detectado!\n"
            
            return output
            
        except Exception as e:
            return f"‚ùå Erro ao detectar outliers: {str(e)}"
    
    def calculate_correlations(self, df: pd.DataFrame, threshold: float = 0.5) -> str:
        """Calcula e analisa correla√ß√µes entre vari√°veis num√©ricas"""
        try:
            numeric_df = df.select_dtypes(include=[np.number])
            
            if len(numeric_df.columns) < 2:
                return "‚ö†Ô∏è √â necess√°rio pelo menos 2 colunas num√©ricas para calcular correla√ß√µes."
            
            corr_matrix = numeric_df.corr()
            
            # Encontra correla√ß√µes fortes
            strong_correlations = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_val = corr_matrix.iloc[i, j]
                    if abs(corr_val) >= threshold:
                        strong_correlations.append({
                            'var1': corr_matrix.columns[i],
                            'var2': corr_matrix.columns[j],
                            'correlation': float(corr_val)
                        })
            
            # Ordena por valor absoluto
            strong_correlations.sort(key=lambda x: abs(x['correlation']), reverse=True)
            
            # Formata output
            output = f"üîó AN√ÅLISE DE CORRELA√á√ïES (threshold: {threshold})\n\n"
            output += f"üìä Matriz de correla√ß√£o: {len(numeric_df.columns)}x{len(numeric_df.columns)}\n"
            output += f"üîç Correla√ß√µes fortes encontradas: {len(strong_correlations)}\n\n"
            
            if strong_correlations:
                output += "üìà CORRELA√á√ïES MAIS FORTES:\n"
                for i, corr in enumerate(strong_correlations[:10], 1):  # Top 10
                    strength = "Muito forte" if abs(corr['correlation']) > 0.8 else "Forte"
                    direction = "positiva" if corr['correlation'] > 0 else "negativa"
                    output += f"{i}. {corr['var1']} ‚Üî {corr['var2']}\n"
                    output += f"   Correla√ß√£o: {corr['correlation']:.3f} ({strength} {direction})\n\n"
            else:
                output += "‚ÑπÔ∏è Nenhuma correla√ß√£o forte encontrada acima do threshold.\n"
            
            # Adiciona matriz completa
            output += "\nüìã MATRIZ DE CORRELA√á√ÉO COMPLETA:\n"
            output += corr_matrix.to_string()
            
            return output
            
        except Exception as e:
            return f"‚ùå Erro ao calcular correla√ß√µes: {str(e)}"
    
    def analyze_categorical(self, df: pd.DataFrame, top_n: int = 10) -> str:
        """Analisa vari√°veis categ√≥ricas"""
        try:
            cat_columns = df.select_dtypes(include=['object']).columns
            
            if len(cat_columns) == 0:
                return "‚ö†Ô∏è Nenhuma coluna categ√≥rica encontrada."
            
            output = f"üìä AN√ÅLISE DE VARI√ÅVEIS CATEG√ìRICAS\n"
            output += f"Total de colunas: {len(cat_columns)}\n\n"
            
            for col in cat_columns:
                unique_count = df[col].nunique()
                most_common = df[col].value_counts().head(top_n)
                missing = df[col].isnull().sum()
                
                output += f"üìã {col}:\n"
                output += f"  ‚Ä¢ Valores √∫nicos: {unique_count}\n"
                output += f"  ‚Ä¢ Valores ausentes: {missing} ({(missing/len(df)*100):.2f}%)\n"
                output += f"  ‚Ä¢ Valores mais frequentes (top {min(top_n, len(most_common))}):\n"
                
                for value, count in most_common.items():
                    pct = (count / len(df)) * 100
                    output += f"    - {value}: {count} ({pct:.2f}%)\n"
                
                output += "\n"
            
            return output
            
        except Exception as e:
            return f"‚ùå Erro ao analisar vari√°veis categ√≥ricas: {str(e)}"
    
    def run_analysis(self, analysis_type: str) -> str:
        """Executa an√°lise baseada no tipo solicitado"""
        if 'data_manager' not in st.session_state:
            return "‚ö†Ô∏è DataManager n√£o inicializado."
        
        df = st.session_state.data_manager.get_dataframe()
        
        if df is None:
            return "‚ö†Ô∏è Nenhum DataFrame carregado."
        
        analysis_type = analysis_type.lower().strip()
        
        if 'basic' in analysis_type or 'estatistic' in analysis_type or 'resumo' in analysis_type:
            return self.get_basic_stats(df)
        
        elif 'outlier' in analysis_type:
            method = 'zscore' if 'zscore' in analysis_type or 'z-score' in analysis_type else 'iqr'
            return self.detect_outliers(df, method)
        
        elif 'correla' in analysis_type:
            threshold = 0.3 if 'fraca' in analysis_type else 0.5
            return self.calculate_correlations(df, threshold)
        
        elif 'categor' in analysis_type:
            return self.analyze_categorical(df)
        
        else:
            return f"""‚ÑπÔ∏è Tipo de an√°lise n√£o reconhecido: '{analysis_type}'

An√°lises dispon√≠veis:
- basic/estatisticas/resumo: Estat√≠sticas b√°sicas completas
- outlier/outliers: Detec√ß√£o de outliers (IQR ou Z-score)
- correlacao/correla√ß√µes: An√°lise de correla√ß√µes
- categorica/categoricas: An√°lise de vari√°veis categ√≥ricas
"""

# Inst√¢ncia global da ferramenta de an√°lise
data_analyzer = DataAnalyzerTool()

def load_csv_tool(filepath: str) -> str:
    """Ferramenta para carregar arquivo CSV"""
    if 'data_manager' not in st.session_state:
        st.session_state.data_manager = DataManager()
    
    result = st.session_state.data_manager.load_csv(filepath)
    return result

def get_dataframe_info_tool(dummy: str = "") -> str:
    """Retorna informa√ß√µes sobre o DataFrame carregado"""
    if 'data_manager' not in st.session_state or st.session_state.data_manager.df is None:
        return "Nenhum arquivo CSV foi carregado ainda. Use a ferramenta 'load_csv' primeiro."
    return st.session_state.data_manager.get_info()

# ============================================
# SISTEMA DE PROMPT DO AGENTE
# ============================================

SYSTEM_PROMPT = """Voc√™ √© um Cientista de Dados Especialista em An√°lise Explorat√≥ria de Dados (EDA).

üéØ SUA MISS√ÉO:
Ajudar usu√°rios a explorar, analisar e extrair insights de arquivos CSV atrav√©s de an√°lises estat√≠sticas e visualiza√ß√µes.

üìä DATASET ATUAL:
O DataFrame est√° dispon√≠vel na vari√°vel 'df'. Use-o diretamente em seus c√≥digos Python.

üõ†Ô∏è FERRAMENTAS DISPON√çVEIS:

1. **get_dataframe_info**: Informa√ß√µes b√°sicas sobre o dataset
   - Use PRIMEIRO quando carregar dados novos
   - Mostra colunas, tipos, shape

2. **data_analyzer**: An√°lises estat√≠sticas avan√ßadas (USE ESTA PRIMEIRO para an√°lises)
   - "basic" ‚Üí Estat√≠sticas completas (m√©dia, mediana, std, assimetria, curtose, missing values)
   - "outlier" ‚Üí Detec√ß√£o de outliers (IQR ou Z-score)
   - "correlacao" ‚Üí Correla√ß√µes entre vari√°veis num√©ricas
   - "categorica" ‚Üí An√°lise de vari√°veis categ√≥ricas
   
3. **python_repl**: C√≥digo Python customizado
   - Use quando data_analyzer n√£o cobrir a an√°lise necess√°ria
   - Para visualiza√ß√µes
   - Para an√°lises temporais
   - Para transforma√ß√µes espec√≠ficas

‚ö° FLUXO DE TRABALHO OTIMIZADO:

**Para perguntas sobre estat√≠sticas/resumo:**
1. Use `data_analyzer` com "basic"
2. Interprete os resultados
‚úÖ R√°pido e completo!

**Para perguntas sobre outliers:**
1. Use `data_analyzer` com "outlier"
2. Se precisar visualizar, use `python_repl` para gr√°fico
‚úÖ An√°lise + visualiza√ß√£o!

**Para perguntas sobre correla√ß√£o:**
1. Use `data_analyzer` com "correlacao"
2. Se precisar heatmap, use `python_repl`
‚úÖ N√∫meros + gr√°fico!

**Para an√°lise de vari√°veis categ√≥ricas:**
1. Use `data_analyzer` com "categorica"
2. Se precisar gr√°ficos de barras, use `python_repl`

**Para visualiza√ß√µes ou an√°lises customizadas:**
1. Use `python_repl` diretamente

üìã EXEMPLOS DE USO:

Pergunta: "Quais as estat√≠sticas b√°sicas?"
‚Üí Use: data_analyzer("basic")
‚Üí Resultado: Estat√≠sticas completas em segundos!

Pergunta: "Existem outliers?"
‚Üí Use: data_analyzer("outlier")
‚Üí Depois (opcional): python_repl para visualizar

Pergunta: "Quais vari√°veis est√£o correlacionadas?"
‚Üí Use: data_analyzer("correlacao")
‚Üí Depois (opcional): python_repl para heatmap

Pergunta: "Valores mais frequentes?"
‚Üí Use: data_analyzer("categorica")

Pergunta: "Tend√™ncias temporais?"
‚Üí Use: python_repl (an√°lise customizada)

Pergunta: "Fa√ßa gr√°fico de X"
‚Üí Use: python_repl

‚ö†Ô∏è REGRAS CR√çTICAS:
1. **SEMPRE prefira data_analyzer** para an√°lises estat√≠sticas padr√£o
2. **Use python_repl** apenas para visualiza√ß√µes ou an√°lises n√£o-padr√£o
3. **SEJA DIRETO**: Execute ferramentas imediatamente, n√£o explique o que VAI fazer
4. **MOSTRE RESULTADOS**: Sempre apresente os n√∫meros e interprete
5. **N√ÉO invente dados**: Use apenas o que as ferramentas retornam

üí° DICAS DE EFICI√äNCIA:
- data_analyzer √© mais r√°pido que python_repl para an√°lises padr√£o
- Combine ferramentas: data_analyzer para n√∫meros + python_repl para gr√°ficos
- Uma ferramenta por vez: execute, analise resultado, depois decida pr√≥ximo passo

üß† LEMBRE-SE:
Voc√™ √© um agente de A√á√ÉO, n√£o apenas de planejamento. Execute, mostre resultados, interprete.
"""

# ============================================
# INICIALIZA√á√ÉO DO AGENTE
# ============================================

@st.cache_resource
def create_agent(api_key, max_iter=15):
    """Cria e configura o agente LangChain"""
    
    # Configura a API key
    api_key = st.secrets["OPENAI_API_KEY"]
    os.environ["OPENAI_API_KEY"] = api_key
    
    # Modelo OpenAI
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1,
        max_tokens=4000
    )

    # Mem√≥ria conversacional
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="output"
    )
    
    # Inst√¢ncia do Python REPL
    if 'python_repl' not in st.session_state:
        st.session_state.python_repl = SafePythonREPL()

    # Ferramentas dispon√≠veis
    tools = [
        Tool(
            name="get_dataframe_info",
            func=get_dataframe_info_tool,
            description="""Retorna informa√ß√µes detalhadas sobre o DataFrame carregado.
            Use PRIMEIRO para conhecer as colunas, tipos de dados e estat√≠sticas b√°sicas.
            Input: qualquer string (ser√° ignorada)
            Output: informa√ß√µes completas do dataset"""
        ),
        Tool(
            name="data_analyzer",
            func=data_analyzer.run_analysis,
            description="""Ferramenta avan√ßada para an√°lise explorat√≥ria de dados.
            
            Tipos de an√°lise dispon√≠veis:
            - "basic" ou "estatisticas" ou "resumo": Estat√≠sticas descritivas completas
              (m√©dia, mediana, desvio padr√£o, assimetria, curtose, valores ausentes)
            
            - "outlier" ou "outliers": Detec√ß√£o de outliers
              - Use "outlier iqr" para m√©todo IQR (padr√£o)
              - Use "outlier zscore" para m√©todo Z-score
            
            - "correlacao" ou "correla√ß√µes": An√°lise de correla√ß√µes entre vari√°veis num√©ricas
              - Use "correlacao fraca" para threshold 0.3
              - Padr√£o: threshold 0.5
            
            - "categorica" ou "categoricas": An√°lise de vari√°veis categ√≥ricas
              (valores √∫nicos, frequ√™ncias, valores mais comuns)
            
            Input: tipo de an√°lise desejada (string)
            Output: an√°lise detalhada formatada
            
            Exemplos de uso:
            - "basic" ‚Üí Estat√≠sticas completas
            - "outlier iqr" ‚Üí Outliers pelo m√©todo IQR
            - "correlacao" ‚Üí Correla√ß√µes fortes (>0.5)
            - "categorica" ‚Üí An√°lise das vari√°veis categ√≥ricas"""
        ),
        Tool(
            name="python_repl",
            description="""Executa c√≥digo Python para an√°lise de dados e visualiza√ß√µes.
            O DataFrame est√° dispon√≠vel como 'df' (j√° carregado e pronto para uso).
            
            Bibliotecas dispon√≠veis: 
            - pandas (pd)
            - numpy (np) 
            - matplotlib.pyplot (plt)
            - seaborn (sns)
            
            Use para:
            - An√°lises customizadas n√£o cobertas pelo data_analyzer
            - Visualiza√ß√µes: histogramas, boxplots, scatter plots, heatmaps
            - Transforma√ß√µes de dados
            - An√°lises temporais
            - Filtros e agrega√ß√µes espec√≠ficas
            
            IMPORTANTE: Sempre use print() para mostrar resultados!
            
            Input: c√≥digo Python v√°lido
            Output: resultado da execu√ß√£o + gr√°ficos gerados"""
        )
    ]

    # Inicializa agente
    agent = initialize_agent(
        tools=tools,
        llm=llm,
        agent=AgentType.OPENAI_FUNCTIONS,
        memory=memory,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=max_iter,  # Configur√°vel
        max_execution_time=120,
        early_stopping_method="generate",
        agent_kwargs={
            "system_message": SystemMessage(content=SYSTEM_PROMPT)
        }
    )

    return agent

# ============================================
# INICIALIZA√á√ÉO DO SESSION STATE
# ============================================

if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'data_manager' not in st.session_state:
    st.session_state.data_manager = DataManager()

if 'plots' not in st.session_state:
    st.session_state.plots = []

if 'python_repl' not in st.session_state:
    st.session_state.python_repl = SafePythonREPL()

# ============================================
# INTERFACE STREAMLIT
# ============================================

# Header
st.title("ü§ñ Agente Aut√¥nomo para An√°lise Explorat√≥ria de Dados")
st.markdown("### üìä Powered by LangChain + OpenAI GPT-4")

st.markdown("""
**Como usar:**
1. Configure sua API Key da OpenAI na barra lateral
2. Fa√ßa upload do seu arquivo CSV
3. Fa√ßa perguntas sobre os dados em linguagem natural
4. Receba an√°lises, estat√≠sticas e visualiza√ß√µes
""")

st.divider()

api_key = st.secrets["OPENAI_API_KEY"]

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # API Key
    # api_key = st.text_input(
    #     "OpenAI API Key",
    #     type="password",
    #     help="Cole sua chave API da OpenAI aqui"
    # )
    
    if api_key:
        st.success("‚úÖ API Key configurada!")
        
        # Configura√ß√£o de itera√ß√µes m√°ximas
        max_iterations = st.slider(
            "M√°ximo de itera√ß√µes do agente",
            min_value=5,
            max_value=30,
            value=15,
            step=5,
            help="N√∫mero m√°ximo de passos que o agente pode executar. Aumente para an√°lises mais complexas."
        )
        
        # Cria o agente com a API key e max_iterations
        if 'agent' not in st.session_state or st.session_state.get('api_key') != api_key or st.session_state.get('max_iter') != max_iterations:
            with st.spinner("Inicializando agente..."):
                st.session_state.agent = create_agent(api_key, max_iterations)
                st.session_state.api_key = api_key
                st.session_state.max_iter = max_iterations
    else:
        st.warning("‚ö†Ô∏è Configure sua API Key para come√ßar")
    
    st.divider()
    
    # Informa√ß√µes sobre ferramentas
    with st.expander("üõ†Ô∏è Ferramentas do Agente"):
        st.markdown("""
        **Data Analyzer (An√°lises R√°pidas):**
        - ‚ö° Estat√≠sticas b√°sicas completas
        - üîó An√°lise de correla√ß√µes
        - üìä An√°lise de vari√°veis categ√≥ricas
        
        **Python REPL (An√°lises Customizadas):**
        - üìà Visualiza√ß√µes e gr√°ficos
        - üîç Transforma√ß√µes espec√≠ficas
        - üé® An√°lises n√£o-padr√£o
        
        üí° O agente escolhe automaticamente a melhor ferramenta!
        """)
    
    # Dicas de uso
    with st.expander("üí° Dicas para usar o agente"):
        st.markdown("""
        **Perguntas r√°pidas (1-3 itera√ß√µes):**
        - "Mostre estat√≠sticas b√°sicas"
        - "Analise correla√ß√µes"
        - "Vari√°veis categ√≥ricas"
        
        **An√°lises m√©dias (5-10 itera√ß√µes):**
        - "Analise correla√ß√£o e crie heatmap"
        - "Detecte outliers e visualize"
        - "Compare grupos A e B"
        
        **An√°lises complexas (10-20 itera√ß√µes):**
        - "An√°lise explorat√≥ria completa com gr√°ficos"
        - "Identifique padr√µes temporais e tend√™ncias"
        - "An√°lise completa de todas as vari√°veis"
        
        ‚ö° **Nova ferramenta Data Analyzer = Respostas mais r√°pidas!**
        """)
    
    st.divider()
    
    # Upload de arquivo
    st.header("üìÅ Upload de Dados")
    uploaded_file = st.file_uploader(
        "Selecione um arquivo CSV",
        type=['csv'],
        help="Fa√ßa upload do arquivo CSV que deseja analisar"
    )
    
    if uploaded_file is not None:
        # Salva o arquivo temporariamente
        temp_path = f"temp_{uploaded_file.name}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        if st.button("üöÄ Carregar CSV", use_container_width=True):
            with st.spinner("Carregando arquivo..."):
                result = st.session_state.data_manager.load_csv(temp_path)
                st.success("Arquivo carregado!")
                with st.expander("üìä Informa√ß√µes do Dataset"):
                    st.text(result)
    
    st.divider()
    
    # Bot√£o para limpar chat
    if st.button("üóëÔ∏è Limpar Conversa", use_container_width=True):
        st.session_state.messages = []
        st.session_state.plots = []
        st.rerun()
    
    # Informa√ß√µes do dataset
    if st.session_state.data_manager.df is not None:
        st.divider()
        st.header("üìä Dataset Info")
        df = st.session_state.data_manager.df
        st.metric("Linhas", f"{df.shape[0]:,}")
        st.metric("Colunas", df.shape[1])
        st.metric("Mem√≥ria", f"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

# Main content
col1, col2 = st.columns([2, 1])

with col1:
    st.header("üí¨ Conversa com o Agente")
    
    # Perguntas sugeridas
    if st.session_state.data_manager.df is not None and len(st.session_state.messages) == 0:
        st.info("üí° **Perguntas sugeridas para come√ßar:**")
        col_a, col_b, col_c = st.columns(3)
        
        with col_a:
            if st.button("üìä Estat√≠sticas b√°sicas", use_container_width=True):
                st.session_state.suggested_question = "Mostre as estat√≠sticas b√°sicas do dataset"
        
        with col_b:
            if st.button("üîç Detectar outliers", use_container_width=True):
                st.session_state.suggested_question = "Detecte outliers nas vari√°veis num√©ricas"
        
        with col_c:
            if st.button("üîó An√°lise de correla√ß√£o", use_container_width=True):
                st.session_state.suggested_question = "Analise as correla√ß√µes entre vari√°veis e mostre as mais fortes"
        
        col_d, col_e, col_f = st.columns(3)
        
        with col_d:
            if st.button("üìã Vari√°veis categ√≥ricas", use_container_width=True):
                st.session_state.suggested_question = "Analise as vari√°veis categ√≥ricas e mostre os valores mais frequentes"
        
        with col_e:
            if st.button("üìà An√°lise explorat√≥ria completa", use_container_width=True):
                st.session_state.suggested_question = "Fa√ßa uma an√°lise explorat√≥ria completa incluindo estat√≠sticas, outliers e correla√ß√µes"
        
        with col_f:
            if st.button("üìâ Visualiza√ß√µes", use_container_width=True):
                st.session_state.suggested_question = "Crie visualiza√ß√µes das principais vari√°veis do dataset"
    
    # Container para mensagens
    chat_container = st.container(height=500)
    
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # Input de mensagem
    prompt = None
    
    # Verifica se h√° pergunta sugerida
    if 'suggested_question' in st.session_state:
        prompt = st.session_state.suggested_question
        del st.session_state.suggested_question
    else:
        prompt = st.chat_input("Digite sua pergunta sobre os dados...", disabled=not api_key)
    
    if prompt:
        if 'agent' not in st.session_state:
            st.error("‚ùå Configure sua API Key primeiro!")
        elif st.session_state.data_manager.df is None:
            st.warning("‚ö†Ô∏è Carregue um arquivo CSV primeiro antes de fazer perguntas!")
        else:
            # Adiciona mensagem do usu√°rio
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Processa resposta do agente
                with st.chat_message("assistant"):
                    with st.spinner("Analisando..."):
                        try:
                            response = st.session_state.agent.run(prompt)
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                        except Exception as e:
                            error_str = str(e)
                            
                            # Verifica se √© erro de limite de itera√ß√µes
                            if "iteration limit" in error_str.lower() or "time limit" in error_str.lower():
                                error_msg = """‚ö†Ô∏è **An√°lise muito complexa!**
                                
O agente atingiu o limite de itera√ß√µes. Isso pode acontecer quando:
- A an√°lise requer muitos passos
- H√° muitas vari√°veis para processar
- A pergunta √© muito abrangente

**Sugest√µes:**
1. Aumente o limite de itera√ß√µes na sidebar (atualmente: {})
2. Divida sua pergunta em partes menores
3. Seja mais espec√≠fico sobre o que deseja analisar

üí° Tentarei responder com o que consegui processar at√© agora...
                                """.format(st.session_state.get('max_iter', 15))
                                
                                st.warning(error_msg)
                                
                                # Tenta obter resposta parcial se houver
                                if hasattr(st.session_state.agent, 'agent') and hasattr(st.session_state.agent.agent, 'return_values'):
                                    partial = st.session_state.agent.agent.return_values.get('output', 'An√°lise incompleta.')
                                    st.markdown(partial)
                                    st.session_state.messages.append({"role": "assistant", "content": error_msg + "\n\n" + partial})
                                else:
                                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
                            else:
                                # Outros erros
                                error_msg = f"‚ùå **Erro ao processar:**\n```\n{error_str}\n```"
                                st.error(error_msg)
                                st.session_state.messages.append({"role": "assistant", "content": error_msg})
            
            st.rerun()

with col2:
    st.header("üìä Gr√°ficos Gerados")
    
    if st.session_state.plots:
        for i, plot_path in enumerate(reversed(st.session_state.plots)):
            if os.path.exists(plot_path):
                st.image(plot_path, caption=f"Gr√°fico {len(st.session_state.plots) - i}", use_container_width=True)
                st.divider()
    else:
        st.info("Nenhum gr√°fico gerado ainda. Pe√ßa ao agente para criar visualiza√ß√µes!")

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    Desenvolvido com ‚ù§Ô∏è usando LangChain e Streamlit
</div>
""", unsafe_allow_html=True)